{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical Evaluation of Sensitivity Bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We examine the sensitivity bounds provided by Best and Grauer, who provide bounds for:\n",
    "\n",
    "* $|h_0|$: the norm of the optimal portfolio. \n",
    "* $|h_1|$: the norm of the deviation portfolio. \n",
    "* $|\\mu_p - \\mu_p^{*}|$: the difference between the mean returns of $h_0$ and $h_0 + h_1$, where $\\mu_p = \\mathbf{h}_0'\\mathbf{\\mu}$ and $\\mu_p^{*} = \\left(\\mathbf{h}_0 + \\mathbf{h}_1\\right)'\\left(\\mathbf{\\mu} + t\\mathbf{q}\\right)$\n",
    "* $|\\sigma_p^2 - \\sigma_\\hat{p}^2|$: the difference between variance of returns $\\mathbf{h}_0$ and $\\mathbf{h}_0 +\\mathbf{h}_1$. The difference in variance between $h_0$ and $h_0+h_1$. \n",
    "\n",
    "We evaluate the bounds using parameters calculated from different datasets, representing realistic parameter choices of $(\\Sigma, \\mu)$. \n",
    "\n",
    "The function ```BGbounds()``` calculates the bounds, values, and actual quantities above. </br>\n",
    "The function ```tangency2()``` calculates the tangency portfolio. </br>\n",
    "The function ```Tol()``` is used to calculate the risk tolerance $T$ for the tangency portfolio. </br>\n",
    "The function ```TestBounds()``` runs the simulation experiment to compare the bounds with the actual values from simulations.\n",
    "\n",
    "To re-rerun experiments, run each cell in the notebook Results.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as linalg\n",
    "from numpy.linalg import eig, norm, cond\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "import csv\n",
    "import os\n",
    "\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tangency portfolio\n",
    "def tangency2(Cov, mu, T):\n",
    "    n = len(Cov)\n",
    "    one = np.ones((n))\n",
    "    invCov = np.linalg.inv(Cov)\n",
    "    # Efficient set constants\n",
    "    a = one.T@invCov@mu\n",
    "    c = one.T@invCov@one\n",
    "    # risk tolerance\n",
    "#     T = 1/a\n",
    "    # tangency portfolio\n",
    "    w = (1/c)*(invCov@one) + T*(invCov@(mu - one*(a/c)))\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best and Grauer Bounds\n",
    "def BGbounds(Cov, mu, q):\n",
    "    # Note that risk tolernance can be negative\n",
    "    n = len(Cov)\n",
    "    one = np.ones((n,1))\n",
    "    invCov = np.linalg.inv(Cov)\n",
    "    mu_hat = mu + q\n",
    "    mu_hat = mu_hat/linalg.norm(mu_hat)*linalg.norm(mu) # fix norm of mu_hat = mu\n",
    "    T = np.abs(1/(one.T@invCov@mu)) # risk tolerance corresponding to \"true\" tangency\n",
    "    t = 1 # scale parameter for change in means vector\n",
    "    # eigenvalues\n",
    "    eig = np.linalg.eig(Cov)[0]\n",
    "    l_max = np.max(eig)\n",
    "    l_min = np.min(eig)\n",
    "    norm_mu = np.linalg.norm(mu)\n",
    "    norm_mu_hat = np.linalg.norm(mu_hat)\n",
    "    norm_q = np.linalg.norm(q)\n",
    "    # bounds\n",
    "    BG_h0 = (1/np.sqrt(n))*(l_max/l_min) + T*(norm_mu_hat/l_min)*(1 + l_max/l_min)\n",
    "    BG_h1 = t*T*(norm_q/l_min)*(1 + l_max/l_min)\n",
    "    BG_mu = T*(norm_q/l_min)*(T*(1 + l_max/l_min)*(2*norm_mu + t*norm_q) + l_max/np.sqrt(n))\n",
    "    BG_sigma = t*T*norm_q*(l_max/(l_min**2))*(1 + l_max/l_min) \\\n",
    "               *(T*(1 + l_max/l_min)*((2*norm_mu + t*norm_q) \\\n",
    "               *(1 + l_max/l_min)) + l_max/np.sqrt(n))\n",
    "    \n",
    "    return BG_h0, BG_h1, BG_mu, BG_sigma\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debugging and deeper investigation\n",
    "def BG_mean_bound(Cov, mu, q):\n",
    "    n = len(Cov)\n",
    "    one = np.ones((n,1))\n",
    "    invCov = np.linalg.inv(Cov)\n",
    "    mu_hat = mu + q\n",
    "    mu_hat = mu_hat/linalg.norm(mu_hat)*linalg.norm(mu) # fix norm of mu_hat = mu\n",
    "    T = np.abs(1/(one.T@invCov@mu)) # risk tolerance corresponding to \"true\" tangency\n",
    "    t = 1 # scale parameter for change in means vector\n",
    "    # eigenvalues\n",
    "    eig = np.linalg.eig(Cov)[0]\n",
    "    l_max = np.max(eig)\n",
    "    l_min = np.min(eig)\n",
    "    norm_mu = np.linalg.norm(mu)\n",
    "    norm_mu_hat = np.linalg.norm(mu_hat)\n",
    "    norm_q = np.linalg.norm(q)\n",
    "    # bounds\n",
    "    BG_mu = T*(norm_q/l_min)*(T*(1 + l_max/l_min)*(2*norm_mu + t*norm_q) + l_max/np.sqrt(n))\n",
    "    term1 = T*(norm_q/l_min)\n",
    "    term2 = T*(1 + l_max/l_min)\n",
    "    term3 = (2*norm_mu + t*norm_q)\n",
    "    term4 = l_max/np.sqrt(n)\n",
    "    \n",
    "    return np.array([T, term1, term2, term3, term4, BG_mu])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for debugging and deeper investigation\n",
    "def BG_cov_bound(Cov, mu, q):\n",
    "    # Note that risk tolernance can be negative\n",
    "    n = len(Cov)\n",
    "    one = np.ones((n,1))\n",
    "    invCov = np.linalg.inv(Cov)\n",
    "    mu_hat = mu + q\n",
    "    mu_hat = mu_hat/linalg.norm(mu_hat)*linalg.norm(mu) # fix norm of mu_hat = mu\n",
    "    T = np.abs(1/(one.T@invCov@mu)) # risk tolerance corresponding to \"true\" tangency\n",
    "    t = 1 # scale parameter for change in means vector\n",
    "    # eigenvalues\n",
    "    eig = np.linalg.eig(Cov)[0]\n",
    "    l_max = np.max(eig)\n",
    "    l_min = np.min(eig)\n",
    "    norm_mu = np.linalg.norm(mu)\n",
    "    norm_mu_hat = np.linalg.norm(mu_hat)\n",
    "    norm_q = np.linalg.norm(q)\n",
    "    # bounds\n",
    "    BG_sigma = t*T*norm_q*(l_max/(l_min**2))*(1 + l_max/l_min) \\\n",
    "               *(T*(1 + l_max/l_min)*((2*norm_mu + t*norm_q) \\\n",
    "               *(1 + l_max/l_min)) + l_max/np.sqrt(n))\n",
    "    term1 = t*T*norm_q*(l_max/(l_min**2))\n",
    "    term2 = T*(1 + l_max/l_min)\n",
    "    term3 = 2*norm_mu + t*norm_q\n",
    "    term4 = l_max/np.sqrt(n)\n",
    "    \n",
    "    return np.array([T, term1, term2, term3, term4, BG_sigma])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate risk tolerance for tangency portfolio\n",
    "def Tol(cov, mu):\n",
    "    n = len(cov)\n",
    "    one = np.ones((n))\n",
    "    invCov = np.linalg.inv(cov)\n",
    "    # Efficient set constants\n",
    "    a = one.T@invCov@mu\n",
    "    return 1/a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestBounds(cov, mu, m):\n",
    "    \"\"\"\n",
    "    Inputs\n",
    "    ---------------------\n",
    "    cov - covariance matrix\n",
    "    mu - mean vector\n",
    "    m - number of samples\n",
    "    T - number of observations for sample. Determines variation in mu_hat. \n",
    "    \"\"\"\n",
    "   \n",
    "    # initialise norm arrays\n",
    "    norm_h0 = np.nan*np.zeros((m))\n",
    "    norm_h1 = np.nan*np.zeros((m))\n",
    "    h1_mu = np.nan*np.zeros((m))\n",
    "    delta_sigma = np.nan*np.zeros((m))\n",
    "     \n",
    "    # Simulation Experiment\n",
    "    #-----------------------\n",
    "    # get dimension\n",
    "    n = np.shape(mu)\n",
    "    # risk tolerance\n",
    "    T = 1/(np.ones((n)).T@linalg.inv(cov)@mu)\n",
    "    # optimal tangency portfolio\n",
    "    opt_t = tangency2(cov, mu, T)\n",
    "    # condition number of covariance\n",
    "    cond = np.linalg.cond(cov)\n",
    "    \n",
    "    # for each sample\n",
    "    for i in range(0,m):\n",
    "        # sample error vector from std MVN\n",
    "        q = np.random.normal(0,1,n)\n",
    "        # length of error vector \n",
    "        r = np.linalg.norm(mu)\n",
    "        # normalise error vector\n",
    "        q = q/np.linalg.norm(q)*r\n",
    "        # calculate sample mean\n",
    "        mu_hat = mu + q\n",
    "        # fix norm\n",
    "        mu_hat = mu_hat/linalg.norm(mu_hat)*linalg.norm(mu)\n",
    "        # estimate tangency portfolio (assuming fixed covariance matrix)\n",
    "        h0 = tangency2(cov, mu_hat, T)\n",
    "        # calculate norm of tangency portfolio\n",
    "        norm_h0[i] = np.linalg.norm(h0) \n",
    "        # calculate error portfolio\n",
    "        h1 = opt_t - h0\n",
    "        # calculate norm of error portfolio\n",
    "        norm_h1[i] = np.linalg.norm(h1)\n",
    "        # calculate difference in mean return\n",
    "        h1_mu[i] = np.abs(h1.T@mu)\n",
    "        # calculate change in variance\n",
    "        delta_sigma[i] = np.abs(h1.T@cov@h0 + h1.T@cov@h1)\n",
    "    \n",
    "    # calculate bounds\n",
    "    BG_h0, BG_h1, BG_mu, BG_sigma = BGbounds(cov, mu, q)\n",
    "    \n",
    "    # calculate ratio between norms and bounds\n",
    "    diff_h0 = BG_h0/norm_h0\n",
    "    diff_h1 = BG_h1/norm_h1\n",
    "    diff_mu_p =  BG_mu/h1_mu\n",
    "    diff_sigma_p = BG_sigma/delta_sigma    \n",
    "    \n",
    "    \n",
    "    # Actual norms results\n",
    "    Actual = pd.DataFrame(data = {'norm_h0': norm_h0, 'norm_h1': norm_h1, \n",
    "                                  'h1_mu': h1_mu, 'delta_sigma': delta_sigma})\n",
    "    # BG Bounds\n",
    "    Bounds = pd.DataFrame(data = {'norm_h0': BG_h0, 'norm_h1': BG_h1, \n",
    "                                  'h1_mu': BG_mu, 'delta_sigma': BG_sigma})\n",
    "    \n",
    "    # Differences\n",
    "    Diff = pd.DataFrame(data = {'norm_h0': diff_h0, 'norm_h1': diff_h1, \n",
    "                                  'h1_mu': diff_mu_p, 'delta_sigma': diff_sigma_p})\n",
    "    \n",
    "    \n",
    "    return Actual, Bounds, Diff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of samples in all simulations\n",
    "m = 100000 # samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1: B&G data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data from Best and Grauer (1991)\n",
    "\n",
    "# Simulation parameters\n",
    "bg_mu = np.array([1.01072,1.017618,1.018270,1.010761,1.019845,1.014452,1.009910,1.016353,1.013755,1.018315])\n",
    "bg_mu -= 1\n",
    "bg    = np.array([\n",
    "        [0.251561e-2,0.765454e-3,0.110378e-2,0.131391e-2,0.157145e-3,0.554516e-3,0.936570e-3,0.164603e-2,0.509158e-3,0.151493e-2],\n",
    "        [0.765454e-3,0.137432e-1,0.284739e-2,0.930502e-3,0.561023e-2,0.345666e-2,0.253434e-3,0.175684e-2,0.180949e-2,0.344478e-2],\n",
    "        [0.110378e-2,0.284738e-2,0.139958e-1,0.102651e-2,0.424560e-2,0.276910e-2,0.758764e-3,0.319972e-2,0.327502e-2,0.362698e-2],\n",
    "        [0.131391e-2,0.930502e-3,0.102651e-2,0.192771e-2,0.450576e-3,0.897736e-3,0.100989e-2,0.164109e-2,0.993300e-3,0.965801e-3],\n",
    "        [0.157145e-3,0.561023e-2,0.424560e-2,0.450576e-3,0.159810e-1,0.349022e-2,0.713579e-3,0.421274e-2,0.297823e-2,0.439917e-2],\n",
    "        [0.554516e-3,0.345666e-2,0.276910e-2,0.897736e-3,0.349022e-2,0.487226e-2,0.643392e-3,0.266937e-2,0.178289e-2,0.265065e-2],\n",
    "        [0.936570e-3,0.253434e-3,0.758764e-3,0.100989e-2,0.713579e-3,0.643392e-3,0.166439e-2,0.101965e-2,0.635091e-3,0.611154e-3],\n",
    "        [0.164603e-2,0.175684e-2,0.319972e-2,0.164109e-2,0.421274e-2,0.266937e-2,0.101965e-2,0.901327e-2,0.153437e-2,0.359597e-2],\n",
    "        [0.509158e-3,0.180949e-2,0.327502e-2,0.993300e-3,0.297823e-2,0.178289e-2,0.635091e-3,0.153437e-2,0.573117e-2,0.215377e-2],\n",
    "        [0.151493e-2,0.344478e-2,0.362698e-2,0.965801e-3,0.439917e-2,0.265065e-2,0.611154e-3,0.359597e-2,0.215377e-2,0.140409e-1]\n",
    "        ])\n",
    "\n",
    "# condition number\n",
    "bg_cond = np.linalg.cond(bg)\n",
    "# bounds vs actual\n",
    "norm_bg1, bounds_bg1, diff_bg1 =  TestBounds(bg, bg_mu, m)\n",
    "\n",
    "print(norm_bg1.min(), '\\n\\n', norm_bg1.median(), '\\n\\n', norm_bg1.max())\n",
    "bounds_bg1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2: J&K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_h0        7.348858e-01\n",
      "norm_h1        7.069418e-01\n",
      "h1_mu          1.304969e-07\n",
      "delta_sigma    1.543860e-08\n",
      "dtype: float64 \n",
      "\n",
      " norm_h0        1.876321\n",
      "norm_h1        1.806790\n",
      "h1_mu          0.002086\n",
      "delta_sigma    0.000247\n",
      "dtype: float64 \n",
      "\n",
      " norm_h0        4.169358\n",
      "norm_h1        4.090660\n",
      "h1_mu          0.012220\n",
      "delta_sigma    0.001446\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# data from Jobson and Korkie (1980)\n",
    "\n",
    "# get data\n",
    "jk_mu  = np.array(pd.read_excel('data/JK_data.xlsx', sheet_name='return')).flatten()\n",
    "jk_cov  = pd.read_excel('data/JK_data.xlsx', sheet_name='cov')\n",
    "jk_cov  = np.array(jk_cov)\n",
    "jk_cond =  np.linalg.cond(jk_cov)\n",
    "\n",
    "# Simulation Parameters\n",
    "# mean and covariance\n",
    "jk_mu = jk_mu/100\n",
    "jk_cov = jk_cov/(100**2)\n",
    "n = len(cov)\n",
    "\n",
    "# condition number\n",
    "cond = np.linalg.cond(cov)\n",
    "\n",
    "# calculate bounds vs actuals\n",
    "norm_jk, bounds_jk, diff_jk =  TestBounds(jk_cov, jk_mu, m)\n",
    "print(norm_jk.min(), '\\n\\n', norm_jk.median(), '\\n\\n', norm_jk.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 3: JSE data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load JSE data\n",
    "jse = pd.read_excel('data/jse_returns_data.xlsx', sheet_name='nolog')\n",
    "jse = jse.drop(['Dates'], axis=1)\n",
    "\n",
    "# calculate moments\n",
    "jse_mu = np.array(jse.mean())\n",
    "jse_cov = np.array(jse.cov())\n",
    "jse_cond = np.linalg.cond(jse_cov)\n",
    "\n",
    "norm_jse, bounds_jse, diff_jse =  TestBounds(jse_cov, jse_mu, m)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm_h0        7.198402e-01\n",
      "norm_h1        7.072584e-01\n",
      "h1_mu          3.087001e-08\n",
      "delta_sigma    3.733383e-10\n",
      "dtype: float64 \n",
      "\n",
      " norm_h0        38.090094\n",
      "norm_h1        38.127235\n",
      "h1_mu           0.003441\n",
      "delta_sigma     0.000042\n",
      "dtype: float64 \n",
      "\n",
      " norm_h0        200.555733\n",
      "norm_h1        199.985652\n",
      "h1_mu            0.020002\n",
      "delta_sigma      0.000242\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(norm_jse.min(), '\\n\\n', norm_jse.median(), '\\n\\n', norm_jse.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 4-11: FF Industry Portfolios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing file 10_Industry_Portfolios.CSV to file\n",
      "writing file 12_Industry_Portfolios.CSV to file\n",
      "writing file 17_Industry_Portfolios.CSV to file\n",
      "writing file 30_Industry_Portfolios.CSV to file\n",
      "writing file 38_Industry_Portfolios.CSV to file\n",
      "writing file 48_Industry_Portfolios.CSV to file\n",
      "writing file 49_Industry_Portfolios.CSV to file\n",
      "writing file 5_Industry_Portfolios.CSV to file\n",
      "Data added: Ind10, Ind12, Ind17, Ind30, Ind38, Ind48, Ind49, Ind5\n"
     ]
    }
   ],
   "source": [
    "# diff_df\n",
    "\n",
    "with open('table_results1.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Data set', 'Condition number', 'min', 'median', 'max', 'min', 'median', 'max', 'min', 'median', 'max', 'min', 'median','max'])\n",
    "    writer.writerow(['BG', bg_cond, diff_bg1.min()[0], diff_bg1.mean()[0], diff_bg1.max()[0], \n",
    "                     diff_bg1.min()[1], diff_bg1.mean()[1], diff_bg1.max()[1], \n",
    "                     diff_bg1.min()[2], diff_bg1.mean()[2], diff_bg1.max()[2], \n",
    "                     diff_bg1.min()[3], diff_bg1.mean()[3], diff_bg1.max()[3]])\n",
    "    writer.writerow(['JK', jk_cond, diff_jk.min()[0], diff_jk.mean()[0], diff_jk.max()[0], \n",
    "                     diff_jk.min()[1], diff_jk.mean()[1], diff_jk.max()[1], \n",
    "                     diff_jk.min()[2], diff_jk.mean()[2], diff_jk.max()[2],\n",
    "                     diff_jk.min()[3], diff_jk.mean()[3], diff_jk.max()[3]])\n",
    "    writer.writerow(['JSE', jse_cond, diff_jse.min()[0], diff_jse.mean()[0], diff_jse.max()[0], \n",
    "                     diff_jse.min()[1], diff_jse.mean()[1], diff_jse.max()[1], \n",
    "                     diff_jse.min()[2], diff_jse.mean()[2], diff_jse.max()[2], \n",
    "                     diff_jse.min()[3], diff_jse.mean()[3], diff_jse.max()[3]])\n",
    "    added = []\n",
    "    for file_name in sorted(os.listdir('data/ff_data')):\n",
    "        \n",
    "        if file_name.endswith('.CSV'):\n",
    "            # import data\n",
    "            df = pd.read_csv( os.path.join('data/ff_data',file_name), header = 6, engine = 'python',  nrows = 1121, index_col =0 )\n",
    "            # replace missing values\n",
    "            df = df.replace(-99.99, np.NaN)\n",
    "            # rescale returns\n",
    "            df /= 100\n",
    "            dfname = 'Ind'+file_name.split('_',1)[0]\n",
    "            added.append(dfname)\n",
    "            exec(\"%s=df\"%dfname)\n",
    "            print(\"writing file %s to file\"%file_name)\n",
    "\n",
    "            # calculate moments\n",
    "            df_mu = np.array(df.mean())\n",
    "            df_cov = np.array(df.cov())\n",
    "            df_cond = np.linalg.cond(df_cov)\n",
    "            # calculate bounds\n",
    "            norm_df, bounds_df, diff_df =  TestBounds(df_cov, df_mu, m)\n",
    "            \n",
    "            # write to csv            \n",
    "            writer.writerow([dfname, df_cond, diff_df.min()[0], diff_df.mean()[0], diff_df.max()[0], diff_df.min()[1], diff_df.mean()[1], diff_df.max()[1], diff_df.min()[2], diff_df.mean()[2], diff_df.max()[2], diff_df.min()[3], diff_df.mean()[3], diff_df.max()[3]])\n",
    "        \n",
    "print(\"Data added: \"+\", \".join(added))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing file 10_Industry_Portfolios.CSV to file\n",
      "writing file 12_Industry_Portfolios.CSV to file\n",
      "writing file 17_Industry_Portfolios.CSV to file\n",
      "writing file 30_Industry_Portfolios.CSV to file\n",
      "writing file 38_Industry_Portfolios.CSV to file\n",
      "writing file 48_Industry_Portfolios.CSV to file\n",
      "writing file 49_Industry_Portfolios.CSV to file\n",
      "writing file 5_Industry_Portfolios.CSV to file\n",
      "Data added: Ind10, Ind12, Ind17, Ind30, Ind38, Ind48, Ind49, Ind5\n"
     ]
    }
   ],
   "source": [
    "# norm_df\n",
    "\n",
    "with open('table_results_norm1.csv', 'w') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Data set', 'Condition number', 'min', 'median', 'max', 'min', 'median', 'max', 'min', 'median', 'max', 'min', 'median','max'])\n",
    "    writer.writerow(['BG', bg_cond, norm_bg1.min()[0], norm_bg1.mean()[0], norm_bg1.max()[0],\n",
    "                     norm_bg1.min()[1], norm_bg1.mean()[1], norm_bg1.max()[1],\n",
    "                     norm_bg1.min()[2], norm_bg1.mean()[2], norm_bg1.max()[2]\n",
    "                     norm_bg1.min()[3], norm_bg1.mean()[3], norm_bg1.max()[3]])\n",
    "    writer.writerow(['JK', jk_cond, norm_jk.min()[0], norm_jk.mean()[0], norm_jk.max()[0],\n",
    "                     norm_jk.min()[1], norm_jk.mean()[1], norm_jk.max()[1], \n",
    "                     norm_jk.min()[2], norm_jk.mean()[2], norm_jk.max()[2], \n",
    "                     norm_jk.min()[3], norm_jk.mean()[3], norm_jk.max()[3]])\n",
    "    writer.writerow(['JSE', jse_cond, norm_jse.min()[0], norm_jse.mean()[0], norm_jse.max()[0],\n",
    "                     norm_jse.min()[1], norm_jse.mean()[1], norm_jse.max()[1],\n",
    "                     norm_jse.min()[2], norm_jse.mean()[2], norm_jse.max()[2],\n",
    "                     norm_jse.min()[3], norm_jse.mean()[3], norm_jse.max()[3]])\n",
    "\n",
    "    # FF datasets\n",
    "    added = []\n",
    "    for file_name in sorted(os.listdir('ff_data')):\n",
    "        if file_name.endswith('.CSV'):\n",
    "            df = pd.read_csv( os.path.join('ff_data',file_name), header = 6, engine = 'python',  nrows = 1121, index_col =0 )\n",
    "            # replace missing data with NaNs\n",
    "            df = df.replace(-99.99, np.NaN)\n",
    "            # rescale from percentage to units\n",
    "            df /= 100\n",
    "            dfname = 'Ind'+file_name.split('_',1)[0]\n",
    "            added.append(dfname)\n",
    "            exec(\"%s=df\"%dfname)\n",
    "            print(\"writing file %s to file\"%file_name)\n",
    "\n",
    "            # calculate moments\n",
    "            df_mu = np.array(df.mean())\n",
    "            df_cov = np.array(df.cov())\n",
    "            df_cond = np.linalg.cond(df_cov)\n",
    "            # compare bounds vs actual\n",
    "            norm_df, bounds_df, diff_df =  TestBounds(df_cov, df_mu, m)\n",
    "\n",
    "            # write to csv            \n",
    "            writer.writerow([dfname, df_cond, norm_df.min()[0], norm_df.mean()[0], norm_df.max()[0], norm_df.min()[1], norm_df.mean()[1], norm_df.max()[1], norm_df.min()[2], norm_df.mean()[2], norm_df.max()[2], norm_df.min()[3], norm_df.mean()[3], norm_df.max()[3]])\n",
    "            \n",
    "            \n",
    "# check datasets added\n",
    "print(\"Data added: \"+\", \".join(added))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing file 10_Industry_Portfolios.CSV to file\n",
      "writing file 12_Industry_Portfolios.CSV to file\n",
      "writing file 17_Industry_Portfolios.CSV to file\n",
      "writing file 30_Industry_Portfolios.CSV to file\n",
      "writing file 38_Industry_Portfolios.CSV to file\n",
      "writing file 48_Industry_Portfolios.CSV to file\n",
      "writing file 49_Industry_Portfolios.CSV to file\n",
      "writing file 5_Industry_Portfolios.CSV to file\n",
      "Data added: Ind10, Ind12, Ind17, Ind30, Ind38, Ind48, Ind49, Ind5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data set</th>\n",
       "      <th>1/sqrt(n)</th>\n",
       "      <th>cond</th>\n",
       "      <th>inv(l_min)</th>\n",
       "      <th>mu</th>\n",
       "      <th>t</th>\n",
       "      <th>T</th>\n",
       "      <th>h0</th>\n",
       "      <th>h1</th>\n",
       "      <th>delta_mu</th>\n",
       "      <th>delta_sigma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BG</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>47.816169</td>\n",
       "      <td>1478.124266</td>\n",
       "      <td>0.048661</td>\n",
       "      <td>0.024330</td>\n",
       "      <td>0.109005</td>\n",
       "      <td>3.978560e+02</td>\n",
       "      <td>3.827352e+02</td>\n",
       "      <td>6.170571</td>\n",
       "      <td>6.941651e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JK</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>47.099865</td>\n",
       "      <td>1005.671668</td>\n",
       "      <td>5.140457</td>\n",
       "      <td>2.570229</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>3.047093e+02</td>\n",
       "      <td>2.941775e+02</td>\n",
       "      <td>5.431153</td>\n",
       "      <td>5.849990e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JSE</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>5534.039408</td>\n",
       "      <td>477973.135449</td>\n",
       "      <td>0.044249</td>\n",
       "      <td>0.022125</td>\n",
       "      <td>0.012094</td>\n",
       "      <td>1.417372e+06</td>\n",
       "      <td>1.415775e+06</td>\n",
       "      <td>2273.781653</td>\n",
       "      <td>3.853622e+14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ind5</td>\n",
       "      <td>0.447214</td>\n",
       "      <td>37.976407</td>\n",
       "      <td>2812.578234</td>\n",
       "      <td>0.022076</td>\n",
       "      <td>0.011038</td>\n",
       "      <td>0.221445</td>\n",
       "      <td>5.528929e+02</td>\n",
       "      <td>5.359093e+02</td>\n",
       "      <td>7.942572</td>\n",
       "      <td>4.535578e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ind10</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>122.610158</td>\n",
       "      <td>4444.619678</td>\n",
       "      <td>0.031471</td>\n",
       "      <td>0.015736</td>\n",
       "      <td>0.154587</td>\n",
       "      <td>2.711622e+03</td>\n",
       "      <td>2.672850e+03</td>\n",
       "      <td>39.199130</td>\n",
       "      <td>7.308585e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ind12</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>151.977117</td>\n",
       "      <td>4345.875126</td>\n",
       "      <td>0.034573</td>\n",
       "      <td>0.017287</td>\n",
       "      <td>0.150264</td>\n",
       "      <td>3.497685e+03</td>\n",
       "      <td>3.453813e+03</td>\n",
       "      <td>54.056783</td>\n",
       "      <td>1.914513e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ind17</td>\n",
       "      <td>0.242536</td>\n",
       "      <td>197.456472</td>\n",
       "      <td>3682.459330</td>\n",
       "      <td>0.040658</td>\n",
       "      <td>0.020329</td>\n",
       "      <td>0.146538</td>\n",
       "      <td>4.402031e+03</td>\n",
       "      <td>4.354141e+03</td>\n",
       "      <td>78.111026</td>\n",
       "      <td>6.052474e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ind30</td>\n",
       "      <td>0.182574</td>\n",
       "      <td>291.431715</td>\n",
       "      <td>3004.442004</td>\n",
       "      <td>0.055630</td>\n",
       "      <td>0.027815</td>\n",
       "      <td>0.132628</td>\n",
       "      <td>6.535553e+03</td>\n",
       "      <td>6.482345e+03</td>\n",
       "      <td>143.874527</td>\n",
       "      <td>3.575914e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ind38</td>\n",
       "      <td>0.164399</td>\n",
       "      <td>387.913607</td>\n",
       "      <td>3333.307987</td>\n",
       "      <td>0.063092</td>\n",
       "      <td>0.031546</td>\n",
       "      <td>0.111524</td>\n",
       "      <td>9.185350e+03</td>\n",
       "      <td>9.121577e+03</td>\n",
       "      <td>192.993846</td>\n",
       "      <td>1.129735e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ind48</td>\n",
       "      <td>0.144338</td>\n",
       "      <td>461.227974</td>\n",
       "      <td>2812.365693</td>\n",
       "      <td>0.072704</td>\n",
       "      <td>0.036352</td>\n",
       "      <td>0.114123</td>\n",
       "      <td>1.085257e+04</td>\n",
       "      <td>1.078600e+04</td>\n",
       "      <td>269.033708</td>\n",
       "      <td>2.645722e+10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ind49</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>812.001603</td>\n",
       "      <td>4843.697890</td>\n",
       "      <td>0.073277</td>\n",
       "      <td>0.036638</td>\n",
       "      <td>0.113694</td>\n",
       "      <td>3.292344e+04</td>\n",
       "      <td>3.280744e+04</td>\n",
       "      <td>820.935466</td>\n",
       "      <td>4.400862e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data set  1/sqrt(n)         cond     inv(l_min)        mu         t  \\\n",
       "0        BG   0.316228    47.816169    1478.124266  0.048661  0.024330   \n",
       "1        JK   0.223607    47.099865    1005.671668  5.140457  2.570229   \n",
       "2       JSE   0.288675  5534.039408  477973.135449  0.044249  0.022125   \n",
       "3      Ind5   0.447214    37.976407    2812.578234  0.022076  0.011038   \n",
       "4     Ind10   0.316228   122.610158    4444.619678  0.031471  0.015736   \n",
       "5     Ind12   0.288675   151.977117    4345.875126  0.034573  0.017287   \n",
       "6     Ind17   0.242536   197.456472    3682.459330  0.040658  0.020329   \n",
       "7     Ind30   0.182574   291.431715    3004.442004  0.055630  0.027815   \n",
       "8     Ind38   0.164399   387.913607    3333.307987  0.063092  0.031546   \n",
       "9     Ind48   0.144338   461.227974    2812.365693  0.072704  0.036352   \n",
       "10    Ind49   0.142857   812.001603    4843.697890  0.073277  0.036638   \n",
       "\n",
       "           T            h0            h1     delta_mu   delta_sigma  \n",
       "0   0.109005  3.978560e+02  3.827352e+02     6.170571  6.941651e+05  \n",
       "1   0.001183  3.047093e+02  2.941775e+02     5.431153  5.849990e+05  \n",
       "2   0.012094  1.417372e+06  1.415775e+06  2273.781653  3.853622e+14  \n",
       "3   0.221445  5.528929e+02  5.359093e+02     7.942572  4.535578e+05  \n",
       "4   0.154587  2.711622e+03  2.672850e+03    39.199130  7.308585e+07  \n",
       "5   0.150264  3.497685e+03  3.453813e+03    54.056783  1.914513e+08  \n",
       "6   0.146538  4.402031e+03  4.354141e+03    78.111026  6.052474e+08  \n",
       "7   0.132628  6.535553e+03  6.482345e+03   143.874527  3.575914e+09  \n",
       "8   0.111524  9.185350e+03  9.121577e+03   192.993846  1.129735e+10  \n",
       "9   0.114123  1.085257e+04  1.078600e+04   269.033708  2.645722e+10  \n",
       "10  0.113694  3.292344e+04  3.280744e+04   820.935466  4.400862e+11  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bounds_df\n",
    "\n",
    "with open('table_results_bounds1.csv', 'w') as file:    \n",
    "    df_bounds = pd.DataFrame(columns = ['Data set', '1/sqrt(n)', 'cond', 'inv(l_min)', 'mu', 't', 'T', 'h0', 'h1', 'delta_mu', 'delta_sigma' ])\n",
    "    df_bounds.loc[0] = ['BG', 1/np.sqrt(len(bg_mu)), bg_cond, 1/eig(bg)[0].min(), norm(bg_mu), norm(bg_mu)/2, Tol(bg,bg_mu), \n",
    "                        bounds_bg1.norm_h0[0], bounds_bg1.norm_h1[0], bounds_bg1.h1_mu[0], bounds_bg1.delta_sigma[0]]\n",
    "    df_bounds.loc[1] = ['JK', 1/np.sqrt(len(jk_mu)), jk_cond, 1/eig(jk_cov)[0].min(), norm(jk_mu), norm(jk_mu)/2, Tol(jk_cov,jk_mu), \n",
    "                        bounds_jk.norm_h0[0], bounds_jk.norm_h1[0], bounds_jk.h1_mu[0], bounds_jk.delta_sigma[0]]\n",
    "    df_bounds.loc[2] = ['JSE', 1/np.sqrt(len(jse_mu)), jse_cond, 1/eig(jse_cov)[0].min(), norm(jse_mu), norm(jse_mu)/2, Tol(jse_cov,jse_mu), \n",
    "                        bounds_jse.norm_h0[0], bounds_jse.norm_h1[0], bounds_jse.h1_mu[0], bounds_jse.delta_sigma[0]]\n",
    "    \n",
    "    added = []\n",
    "    i = 3 # counter\n",
    "    for file_name in sorted(os.listdir('data/ff_data')):\n",
    "        \n",
    "        if file_name.endswith('.CSV'):\n",
    "            df = pd.read_csv( os.path.join('data/ff_data',file_name), header = 6, engine = 'python',  nrows = 1121, index_col =0 )\n",
    "            # replace missing with NaNs\n",
    "            df = df.replace(-99.99, np.NaN)\n",
    "            # rescalt percentages to units\n",
    "            df /= 100\n",
    "            dfname = 'Ind'+file_name.split('_',1)[0]\n",
    "            added.append(dfname)\n",
    "            exec(\"%s=df\"%dfname)\n",
    "            print(\"writing file %s to file\"%file_name)\n",
    "   \n",
    "            # calculate moments\n",
    "            df_mu = np.array(df.mean())\n",
    "            df_cov = np.array(df.cov())\n",
    "            df_cond = np.linalg.cond(df_cov)\n",
    "            # store moments for each FF dataset\n",
    "            exec(\"%s_mu = np.array(df.mean())\"%dfname)\n",
    "            exec(\"%s_cov = np.array(df.cov())\"%dfname)\n",
    "            exec(\"%s_cond = np.linalg.cond(df_cov)\"%dfname)\n",
    "            # compare bounds to actuals\n",
    "            norm_df, bounds_df, diff_df =  TestBounds(df_cov, df_mu, m)\n",
    "            exec(\"norm_%s, bounds_%s, diff_%s =  TestBounds(df_cov, df_mu, m)\"%(dfname, dfname, dfname))\n",
    "            \n",
    "            # wtite to DF\n",
    "            df_bounds.loc[i] = [dfname, 1/np.sqrt(len(df_mu)), df_cond, 1/eig(df_cov)[0].min(), norm(df_mu), norm(df_mu/2), Tol(df_cov, df_mu), \n",
    "                                bounds_df.norm_h0[0], bounds_df.norm_h1[0], bounds_df.h1_mu[0], bounds_df.delta_sigma[0]]\n",
    "            # increase counter\n",
    "            i+=1 \n",
    "            \n",
    "        \n",
    "print(\"Data added: \"+\", \".join(added))\n",
    "\n",
    "# change index of Ind5 results\n",
    "df_bounds.loc[2.5] = df_bounds.loc[10]\n",
    "df_bounds = df_bounds.sort_index().drop(10).reset_index(drop=True)\n",
    "# write to csv\n",
    "df_bounds.to_csv('table_results_bounds1.csv')\n",
    "df_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Additional Calcs\n",
    "\n",
    "1. Comparing largest bound (JSE) to smallest bound (Ind5) for $|\\mathbf{h}_0|$ and $|\\mathbf{h}_1|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>norm_h0</th>\n",
       "      <th>norm_h1</th>\n",
       "      <th>h1_mu</th>\n",
       "      <th>delta_sigma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2563.556974</td>\n",
       "      <td>2641.817974</td>\n",
       "      <td>286.277762</td>\n",
       "      <td>8.496431e+08</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       norm_h0      norm_h1       h1_mu   delta_sigma\n",
       "0  2563.556974  2641.817974  286.277762  8.496431e+08"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds_jse/bounds_Ind5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "norm_h0        14.186533\n",
       "norm_h1        14.204922\n",
       "h1_mu           2.507731\n",
       "delta_sigma     0.136956\n",
       "dtype: float64"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(norm_jse.max())/(norm_Ind5.max())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
